{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machin.frame.algorithms import DDPGPer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from drl4dypm.env import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without action\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(state_dim, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, action_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        a = torch.relu(self.fc1(state))\n",
    "        a = torch.relu(self.fc2(a))\n",
    "        a = self.softmax(self.fc3(a))\n",
    "        return a\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(state_dim + action_dim, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        state_action = torch.cat([state, action], 1)\n",
    "        q = torch.relu(self.fc1(state_action))\n",
    "        q = torch.relu(self.fc2(q))\n",
    "        q = self.fc3(q)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(state_dim+action_dim, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, action_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, state, last_action):\n",
    "        a = torch.cat([state, last_action], 1)\n",
    "        a = torch.relu(self.fc1(a))\n",
    "        a = torch.relu(self.fc2(a))\n",
    "        a = self.softmax(self.fc3(a))\n",
    "        return a\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(state_dim + 2*action_dim, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, state, last_action, action):\n",
    "        state_action = torch.cat([state, last_action, action], 1)\n",
    "        q = torch.relu(self.fc1(state_action))\n",
    "        q = torch.relu(self.fc2(q))\n",
    "        q = self.fc3(q)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Actor, self).__init__()\n",
    "        \n",
    "        self.lstm_out = 20*10*2\n",
    "        self.lstm = nn.LSTM(state_dim, 20, 2, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(self.lstm_out, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, action_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        a = torch.relu(self.lstm(state)[0].reshape(-1,self.lstm_out))\n",
    "        a = torch.relu(self.fc1(a))\n",
    "        a = torch.relu(self.fc2(a))\n",
    "        a = self.softmax(self.fc3(a))\n",
    "        return a\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.lstm_out = 20*10*2\n",
    "        self.lstm = nn.LSTM(state_dim, 20, 2, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(self.lstm_out, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        a = torch.relu(self.lstm(state)[0].reshape(-1,self.lstm_out))\n",
    "        state_action = torch.cat([a, action], 1)\n",
    "        q = torch.relu(self.fc1(state_action))\n",
    "        q = torch.relu(self.fc2(q))\n",
    "        q = self.fc3(q)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment params\n",
    "trading_days = 252\n",
    "# asset_names = ['AAL','AMZN','GOOG','FB','TSLA','CVS','FDX']\n",
    "asset_names = ['AAL','CVS','FDX','F','AIG','CAT']\n",
    "k = 10\n",
    "cost_bps = 1e-3\n",
    "# path_to_data = 'data/stock_price.csv'\n",
    "path_to_data = 'data/stock_price_1D.csv'\n",
    "\n",
    "# agent params\n",
    "num_assets = len(asset_names)\n",
    "state_dim = 3*num_assets\n",
    "action_dim = 1+num_assets\n",
    "\n",
    "# training params\n",
    "max_episode = 100\n",
    "min_episode_to_train = 10\n",
    "\n",
    "\n",
    "noise_param = (0, 0.01)\n",
    "noise_mode = \"normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2021-03-07 16:22:58,042] <WARNING>:default_logger:The reduction property of criterion is not 'none', automatically corrected.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "actor = Actor(state_dim*k, action_dim,)\n",
    "actor_t = Actor(state_dim*k, action_dim)\n",
    "critic = Critic(state_dim*k, action_dim)\n",
    "critic_t = Critic(state_dim*k, action_dim)\n",
    "\n",
    "ddpg_per = DDPGPer(actor, actor_t, critic, critic_t,\n",
    "                   torch.optim.Adam,\n",
    "                   nn.MSELoss(reduction='sum'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TradingEnvironment(num_steps=trading_days, \n",
    "                         asset_names=asset_names, \n",
    "                         k=k, \n",
    "                         cost_bps=cost_bps,\n",
    "                         agent_names=['base'],\n",
    "                         path_to_data=path_to_data,\n",
    "                         reward_scale_factor=1\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2021-03-07 16:24:52,714] <WARNING>:default_logger:You have not specified the i/o device of your model <class '__main__.Actor'>, automatically determined and set to: cpu\n",
      "The framework is not responsible for any un-matching device issues caused by this operation.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode     |reward      |critic_loss |actor_loss  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2021-03-07 16:24:53,408] <WARNING>:default_logger:You have not specified the i/o device of your model <class '__main__.Actor'>, automatically determined and set to: cpu\n",
      "The framework is not responsible for any un-matching device issues caused by this operation.\u001b[0m\n",
      "\u001b[33m[2021-03-07 16:24:53,410] <WARNING>:default_logger:You have not specified the i/o device of your model <class '__main__.Critic'>, automatically determined and set to: cpu\n",
      "The framework is not responsible for any un-matching device issues caused by this operation.\u001b[0m\n",
      "\u001b[33m[2021-03-07 16:24:53,411] <WARNING>:default_logger:You have not specified the i/o device of your model <class '__main__.Critic'>, automatically determined and set to: cpu\n",
      "The framework is not responsible for any un-matching device issues caused by this operation.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           |0.8777      |0.0002      |-0.1300     \n",
      "1           |1.6425      |0.0003      |-0.0995     \n",
      "2           |2.3271      |0.0001      |-0.0588     \n",
      "3           |2.8785      |0.0003      |-0.0103     \n",
      "4           |3.4439      |0.0003      |0.0379      \n",
      "5           |3.9524      |0.0003      |0.0742      \n",
      "6           |4.4288      |0.0003      |0.1111      \n",
      "7           |4.8399      |0.0003      |0.1556      \n",
      "8           |5.1882      |0.0004      |0.2179      \n",
      "9           |5.5283      |0.0004      |0.2587      \n",
      "10          |5.8383      |0.0006      |0.2995      \n",
      "11          |6.1015      |0.0007      |0.3050      \n",
      "12          |6.2857      |0.0008      |0.3435      \n",
      "13          |6.5074      |0.0006      |0.4106      \n",
      "14          |6.7557      |0.0009      |0.4337      \n",
      "15          |6.9239      |0.0006      |0.4485      \n",
      "16          |7.1098      |0.0013      |0.4849      \n",
      "17          |7.2645      |0.0009      |0.5054      \n",
      "18          |7.4014      |0.0009      |0.5520      \n",
      "19          |7.4939      |0.0013      |0.5622      \n",
      "20          |7.5803      |0.0016      |0.5778      \n",
      "21          |7.6596      |0.0014      |0.6418      \n",
      "22          |7.7109      |0.0007      |0.6361      \n",
      "23          |7.8173      |0.0022      |0.6692      \n",
      "24          |7.8596      |0.0007      |0.7254      \n",
      "25          |7.9591      |0.0009      |0.7299      \n",
      "26          |8.0162      |0.0012      |0.7603      \n",
      "27          |8.0985      |0.0008      |0.7876      \n",
      "28          |8.1840      |0.0021      |0.7919      \n",
      "29          |8.1683      |0.0018      |0.8373      \n",
      "30          |8.1397      |0.0017      |0.8528      \n",
      "31          |8.1330      |0.0025      |0.8791      \n",
      "32          |8.1687      |0.0020      |0.8996      \n",
      "33          |8.2076      |0.0023      |0.9078      \n",
      "34          |8.2514      |0.0016      |0.9578      \n",
      "35          |8.2552      |0.0016      |0.9736      \n",
      "36          |8.2773      |0.0043      |0.9571      \n",
      "37          |8.2560      |0.0022      |1.0105      \n",
      "38          |8.3155      |0.0030      |1.0041      \n",
      "39          |8.2996      |0.0017      |1.0259      \n",
      "40          |8.3344      |0.0026      |1.0649      \n",
      "41          |8.2980      |0.0032      |1.0610      \n",
      "42          |8.3564      |0.0047      |1.0723      \n",
      "43          |8.3674      |0.0038      |1.1229      \n",
      "44          |8.3317      |0.0021      |1.1232      \n",
      "45          |8.3207      |0.0043      |1.1343      \n",
      "46          |8.3085      |0.0030      |1.1562      \n",
      "47          |8.3348      |0.0014      |1.1905      \n",
      "48          |8.3731      |0.0017      |1.1773      \n",
      "49          |8.4258      |0.0041      |1.2071      \n",
      "50          |8.3856      |0.0020      |1.4931      \n",
      "51          |8.3527      |0.0015      |1.5686      \n",
      "52          |8.3031      |0.0047      |1.6002      \n",
      "53          |8.3338      |0.0068      |1.6205      \n",
      "54          |8.3324      |0.0079      |1.6493      \n",
      "55          |8.2710      |0.0064      |1.6534      \n",
      "56          |8.3128      |0.0064      |1.6572      \n",
      "57          |8.2562      |0.0040      |1.6685      \n",
      "58          |8.2401      |0.0069      |1.6822      \n",
      "59          |8.2083      |0.0028      |1.7076      \n",
      "60          |8.2188      |0.0028      |1.6838      \n",
      "61          |8.3002      |0.0045      |1.7078      \n",
      "62          |8.3588      |0.0042      |1.6907      \n",
      "63          |8.3961      |0.0086      |1.6880      \n",
      "64          |8.3795      |0.0079      |1.7040      \n",
      "65          |8.3428      |0.0097      |1.7125      \n",
      "66          |8.2690      |0.0031      |1.7072      \n",
      "67          |8.2630      |0.0031      |1.7283      \n",
      "68          |8.2258      |0.0031      |1.7471      \n",
      "69          |8.2163      |0.0089      |1.7781      \n",
      "70          |8.2810      |0.0060      |1.7859      \n",
      "71          |8.2917      |0.0078      |1.7784      \n",
      "72          |8.3204      |0.0052      |1.7776      \n",
      "73          |8.3310      |0.0043      |1.7775      \n",
      "74          |8.3413      |0.0080      |1.8007      \n",
      "75          |8.3884      |0.0061      |1.8188      \n",
      "76          |8.3618      |0.0108      |1.8049      \n",
      "77          |8.3974      |0.0092      |1.9767      \n",
      "78          |8.4254      |0.0095      |2.0200      \n",
      "79          |8.4162      |0.0155      |1.9954      \n",
      "80          |8.4036      |0.0123      |1.9918      \n",
      "81          |8.4080      |0.0082      |2.0147      \n",
      "82          |8.4617      |0.0065      |2.0191      \n",
      "83          |8.5073      |0.0123      |1.9992      \n",
      "84          |8.5771      |0.0086      |2.0139      \n",
      "85          |8.5558      |0.0103      |2.0177      \n",
      "86          |8.5593      |0.0093      |2.0125      \n",
      "87          |8.5936      |0.0109      |2.0267      \n",
      "88          |8.6287      |0.0079      |2.0327      \n",
      "89          |8.6106      |0.0121      |2.0090      \n",
      "90          |8.6440      |0.0084      |2.0120      \n",
      "91          |8.6940      |0.0157      |2.0157      \n",
      "92          |8.7226      |0.0039      |2.0069      \n",
      "93          |8.7289      |0.0056      |1.9942      \n",
      "94          |8.6847      |0.0040      |2.0177      \n",
      "95          |8.6505      |0.0076      |2.0322      \n",
      "96          |8.5920      |0.0113      |2.0806      \n",
      "97          |8.5779      |0.0120      |2.0898      \n",
      "98          |8.6097      |0.0090      |2.0958      \n",
      "99          |8.6209      |0.0082      |2.1570      \n"
     ]
    }
   ],
   "source": [
    "cols = ['episode','reward','critic_loss','actor_loss']\n",
    "line = '|'.join([f'{col:<12}' for col in cols])\n",
    "print(line)\n",
    "\n",
    "smoothed_total_reward = 0\n",
    "\n",
    "\n",
    "for e in range(max_episode):\n",
    "    total_reward = 0\n",
    "    state, end = env.init_step()\n",
    "    last_actions = env.simulator.last_actions\n",
    "    \n",
    "    while not end:\n",
    "        with torch.no_grad():\n",
    "            # generate action\n",
    "            action = ddpg_per.act_with_noise(\n",
    "                {'state': torch.tensor(state[1], dtype=torch.float32).view(1,-1),\n",
    "                'last_action': torch.tensor(last_actions['base'], dtype=torch.float32).view(1,-1)},\n",
    "                noise_param=noise_param,\n",
    "                mode=noise_mode\n",
    "            )\n",
    "        \n",
    "            # execute action and move to next step\n",
    "            actions = {'base': action.numpy().reshape(-1)}\n",
    "            rewards, next_state, end = env.take_step(actions, state[0])\n",
    "            \n",
    "            # store experience\n",
    "            ddpg_per.store_transition({\n",
    "                'state': {'state': torch.tensor(state[1], dtype=torch.float32).view(1,-1),\n",
    "                         'last_action': torch.tensor(last_actions['base'], dtype=torch.float32).view(1,-1)},\n",
    "                'action': {'action': torch.tensor(actions['base'], dtype=torch.float32).view(1,-1)},\n",
    "                'next_state': {'state': torch.tensor(next_state[1], dtype=torch.float32).view(1,-1),\n",
    "                              'last_action': torch.tensor(actions['base'], dtype=torch.float32).view(1,-1)},\n",
    "                'reward': rewards['base'],\n",
    "                'terminal': end\n",
    "            })\n",
    "            \n",
    "            \n",
    "        state = next_state\n",
    "        last_actions = actions\n",
    "        \n",
    "        total_reward += rewards['base']\n",
    "    \n",
    "    \n",
    "    for _ in range(trading_days):\n",
    "        actor_loss, critic_loss = ddpg_per.update()\n",
    "        \n",
    "    \n",
    "    smoothed_total_reward = (smoothed_total_reward * 0.9 +\n",
    "                         total_reward * 0.1)\n",
    "\n",
    "    \n",
    "    line = f'{e:<12}|' + '|'.join([f'{col:<12.4f}' for col in [smoothed_total_reward, critic_loss, actor_loss,]])\n",
    "    \n",
    "    print(line)\n",
    "    \n",
    "    env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode     |reward      |critic_loss |actor_loss  \n",
      "0           |0.8563      |1019.7191   |724.9994    \n",
      "1           |1.6298      |94.5890     |745.6669    \n",
      "2           |2.3550      |1014.6796   |755.8207    \n",
      "3           |3.0166      |968.8516    |766.0856    \n",
      "4           |3.5588      |346.4882    |767.2852    \n",
      "5           |4.0107      |873.3723    |762.9828    \n",
      "6           |4.3967      |503.6833    |756.4333    \n",
      "7           |4.7507      |641.8921    |752.8463    \n",
      "8           |5.1071      |1060.1573   |743.0658    \n",
      "9           |5.4160      |281.6003    |739.4130    \n",
      "10          |5.7740      |443.4556    |724.6275    \n",
      "11          |6.0103      |646.4091    |716.1813    \n",
      "12          |6.2924      |365.4511    |736.3979    \n",
      "13          |6.5409      |539.7708    |755.8531    \n",
      "14          |6.7320      |198.5395    |762.7327    \n",
      "15          |6.9298      |654.8489    |764.5886    \n",
      "16          |7.1208      |136.3229    |764.9364    \n",
      "17          |7.2766      |322.9198    |766.0290    \n",
      "18          |7.3969      |334.0739    |762.2795    \n",
      "19          |7.5028      |178.0609    |757.5051    \n",
      "20          |7.6281      |461.6791    |749.0488    \n",
      "21          |7.6713      |395.5329    |741.7054    \n",
      "22          |7.7566      |228.4456    |735.3038    \n",
      "23          |7.8346      |509.2062    |724.8407    \n",
      "24          |7.9166      |233.6307    |718.9235    \n",
      "25          |7.9688      |73.6971     |710.9735    \n",
      "26          |8.0229      |554.6823    |697.6189    \n",
      "27          |8.0603      |473.7994    |688.8535    \n",
      "28          |8.1080      |399.4276    |692.4276    \n",
      "29          |8.1576      |541.5602    |701.1676    \n",
      "30          |8.2074      |1229.5414   |708.7961    \n",
      "31          |8.2420      |244.0878    |711.3356    \n",
      "32          |8.2993      |334.2854    |715.7719    \n",
      "33          |8.3290      |193.1941    |714.6278    \n",
      "34          |8.3627      |752.0439    |713.2628    \n",
      "35          |8.3882      |605.8223    |711.8781    \n",
      "36          |8.4052      |369.3755    |707.1688    \n",
      "37          |8.4562      |112.9885    |701.2001    \n",
      "38          |8.4678      |413.5586    |702.4573    \n",
      "39          |8.4971      |225.8451    |694.6477    \n",
      "40          |8.5141      |515.4074    |685.8720    \n",
      "41          |8.5075      |401.3683    |678.8533    \n",
      "42          |8.5300      |229.3981    |668.4686    \n",
      "43          |8.5221      |422.2215    |663.6549    \n",
      "44          |8.5041      |139.6245    |657.9471    \n",
      "45          |8.5247      |106.9655    |649.8237    \n",
      "46          |8.5239      |82.1283     |644.2589    \n",
      "47          |8.5298      |301.0009    |634.4996    \n",
      "48          |8.5189      |978.8300    |624.9396    \n",
      "49          |8.5299      |55.2032     |617.7209    \n",
      "50          |8.5302      |127.5647    |608.4429    \n",
      "51          |8.5364      |280.1483    |600.5229    \n",
      "52          |8.5294      |121.2842    |594.5772    \n",
      "53          |8.5178      |259.5150    |587.2090    \n",
      "54          |8.5353      |74.4572     |579.0853    \n",
      "55          |8.5300      |187.5596    |570.8819    \n",
      "56          |8.5451      |283.4755    |564.8870    \n",
      "57          |8.5396      |124.7893    |558.8447    \n",
      "58          |8.5234      |92.8020     |547.0540    \n",
      "59          |8.5563      |104.6243    |542.0239    \n",
      "60          |8.5447      |293.7460    |535.8134    \n",
      "61          |8.5499      |315.6587    |524.6905    \n",
      "62          |8.5431      |172.2353    |519.9741    \n",
      "63          |8.5711      |147.3374    |510.6455    \n",
      "64          |8.5888      |250.1434    |506.8843    \n",
      "65          |8.5875      |86.7420     |498.8680    \n",
      "66          |8.5710      |231.9636    |490.9585    \n",
      "67          |8.5799      |69.3729     |481.6975    \n",
      "68          |8.5923      |423.8117    |476.5134    \n",
      "69          |8.6045      |112.4946    |470.7517    \n",
      "70          |8.6163      |80.3386     |465.0790    \n",
      "71          |8.6228      |523.1966    |453.9556    \n",
      "72          |8.6201      |48.5960     |450.1771    \n",
      "73          |8.6082      |102.0984    |442.6483    \n",
      "74          |8.6227      |153.4065    |437.9616    \n",
      "75          |8.6047      |103.3741    |428.9097    \n",
      "76          |8.5930      |62.5857     |420.2011    \n",
      "77          |8.6140      |98.3744     |416.4675    \n",
      "78          |8.6146      |158.3265    |411.3473    \n",
      "79          |8.6330      |71.4049     |404.9672    \n",
      "80          |8.6147      |88.6994     |398.8468    \n",
      "81          |8.6178      |85.3538     |392.1322    \n",
      "82          |8.6035      |111.5320    |386.3690    \n",
      "83          |8.6091      |76.2603     |380.6891    \n",
      "84          |8.6055      |15.9475     |373.3295    \n",
      "85          |8.6200      |129.1357    |370.5480    \n",
      "86          |8.5645      |200.7457    |367.4163    \n",
      "87          |8.5544      |38.0991     |364.5111    \n",
      "88          |8.5611      |53.4111     |364.3002    \n",
      "89          |8.6359      |39.9226     |364.0497    \n",
      "90          |8.6373      |83.3917     |364.9732    \n",
      "91          |8.6054      |102.4921    |359.8773    \n",
      "92          |8.6277      |45.2697     |355.3192    \n",
      "93          |8.5637      |37.7640     |352.9600    \n",
      "94          |8.5366      |50.5529     |349.3581    \n",
      "95          |8.5180      |64.9484     |339.2440    \n",
      "96          |8.5318      |79.7597     |335.4327    \n",
      "97          |8.5665      |49.1121     |329.4108    \n",
      "98          |8.6068      |187.1641    |326.5557    \n",
      "99          |8.6230      |76.4532     |318.1824    \n"
     ]
    }
   ],
   "source": [
    "cols = ['episode','reward','critic_loss','actor_loss']\n",
    "line = '|'.join([f'{col:<12}' for col in cols])\n",
    "print(line)\n",
    "\n",
    "smoothed_total_reward = 0\n",
    "\n",
    "\n",
    "for e in range(max_episode):\n",
    "    total_reward = 0\n",
    "    state, end = env.init_step()\n",
    "    \n",
    "    while not end:\n",
    "        with torch.no_grad():\n",
    "            # generate action\n",
    "            action = ddpg_per.act_with_noise(\n",
    "                {'state': torch.tensor(state[1], dtype=torch.float32).view(1,-1)},\n",
    "                noise_param=noise_param,\n",
    "                mode=noise_mode\n",
    "            )\n",
    "        \n",
    "            # execute action and move to next step\n",
    "            actions = {'base': action.numpy().reshape(-1)}\n",
    "            rewards, next_state, end = env.take_step(actions, state[0])\n",
    "            \n",
    "            # store experience\n",
    "            ddpg_per.store_transition({\n",
    "                'state': {'state': torch.tensor(state[1], dtype=torch.float32).view(1,-1)},\n",
    "                'action': {'action': torch.tensor(actions['base'], dtype=torch.float32).view(1,-1)},\n",
    "                'next_state': {'state': torch.tensor(next_state[1], dtype=torch.float32).view(1,-1)},\n",
    "                'reward': rewards['base'],\n",
    "                'terminal': end\n",
    "            })\n",
    "            \n",
    "            \n",
    "        state = next_state\n",
    "        total_reward += rewards['base']\n",
    "    \n",
    "    \n",
    "    for _ in range(trading_days):\n",
    "        actor_loss, critic_loss = ddpg_per.update()\n",
    "        \n",
    "    \n",
    "    smoothed_total_reward = (smoothed_total_reward * 0.9 +\n",
    "                         total_reward * 0.1)\n",
    "\n",
    "    \n",
    "    line = f'{e:<12}|' + '|'.join([f'{col:<12.4f}' for col in [smoothed_total_reward, critic_loss, actor_loss,]])\n",
    "    \n",
    "    print(line)\n",
    "    \n",
    "    env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "276.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
